{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs In Real Time with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "It lets you go beyond just looking at scalars like losses and accuracies during training and gives \n",
    "you full visibility into all tensors 'flowing through the graph' during training. Tornasole helps you to monitor your training in near real time using rules and would provide you alerts, once it has detected inconsistency in training flow.\n",
    "\n",
    "Using Tornasole is a two step process: Saving tensors and Analysis. Let's look at each one of them closely.\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Tornasole exposes a library which allows you to capture these tensors and save them for analysis.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "There are two ways to get to tensors and run analysis on them. One way is to use concept called ***Rules***. Please refer to [DeveloperGuide_Rules.md](../../../../rules/DeveloperGuide_Rules.md) for more details about rules based approach to analysis. Focus of this notebook is on another way of analysis: **Manual**.\n",
    "\n",
    "Manual analysis is what you use when there are no rules available to detect type of an issue you are running into and you need to get to raw tensors in order to understand what data is travelling through your model duing training and, hopefully, root cause a problem or two with your training job.\n",
    "\n",
    "Manual analysis is powered by Tornasole API - a framework that allows to retrieve tensors and scalas (e.g. debugging data) saved during training job via few lines of code. One of the most powerful features provided by it is real time access to data - you can get tensors and scalars ***while your training job is running***.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a \n",
    "SageMaker training job and using Tornasole API to access those tensors while training is running. We will use small gluon CNN model and train it on FashionMNIST dataset. While job is running we will retrieve activations of first convolutional layer from each 100 batches and visualize them. Also we will visualize weights of that level after the job is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and provide access to Tornasole API to retrieve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://tornasole-external-preview-use1/ ./tornasole\n",
    "!pip install ./smdebug/sdk/ts-binaries/tornasole_mxnet/py3/latest/tornasole-0.3.4-py2.py3-none-any.whl --user\n",
    "!pip -q install ./smdebug/sdk/sagemaker-tornasole-latest.tar.gz\n",
    "!aws configure add-model --service-model file:///home/ec2-user/SageMaker/smdebug/sdk/sagemaker-smdebug.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MXNet models in SageMaker with Tornasole\n",
    "\n",
    "We'll be training a small mxnet CNN model with FashonMNIST dataset in this notebook with Tornasole enabled. This will be done using SageMaker MXNet 1.4.1 Container with Script Mode. Note that Tornasole currently only works with python3, so be sure to set `py_version='py3'` when creating SageMaker Estimator.\n",
    "\n",
    "Let us first train with a simple training script mnist_gluon_realtime_visualize_demo.py with Tornasole enabled in SageMaker using the SageMaker Estimator API. In this example, for simplicity sake, Tornasole will capture all tensors as specified in its configuration every 100 steps (1 step is 1 batch). While training job is running we will use Tornasole API to access saved tensors in real time and visualize them. We will rely on Tornasole to take care of downloading fresh set of tensors every time we query for them.\n",
    "\n",
    "## Enable Tornasole in the training script\n",
    "\n",
    "Integrating Tornasole into the training job can be accomplished by following steps below.\n",
    "\n",
    "### Import the hook package\n",
    "Import the SessionHook class along with other helper classes in your training script as shown below\n",
    "\n",
    "```\n",
    "from smdebug.mxnet import SessionHook\n",
    "from smdebug import SaveConfig, modes\n",
    "```\n",
    "\n",
    "### Instantiate and initialize hook\n",
    "\n",
    "```\n",
    "    # Create SaveConfig object that instructs engine to log graph tensors every 100 steps (1 step == 1 batch).\n",
    "    save_config = SaveConfig(save_interval=100)\n",
    "    # Create a hook that logs ***all*** tensors while training the model.\n",
    "    hook = SessionHook(save_config=save_config, save_all=True)\n",
    "```\n",
    "\n",
    "### Register Tornasole hook to the model before starting of the training.\n",
    "\n",
    "<span style='color:red'>*NOTE: The hook can only be registered to Gluon Non-hybrid models.\n",
    "*</span>\n",
    "\n",
    "After creating or loading the desired model, you can register Tornasole hook with the model as shown below.\n",
    "\n",
    "```\n",
    "# Create a Gluon Model.\n",
    "net = create_gluon_model()\n",
    "\n",
    "# Create a hook for logging all tensors.\n",
    "hook = create_hook()\n",
    "\n",
    "# Apply hook to the model (e.g. instruct engine to recognize hook configuration\n",
    "# and enable mode in which engine will log graph tensors\n",
    "hook.register_hook(net)\n",
    "```\n",
    "\n",
    "#### Set the mode\n",
    "Tornasole has the concept of modes (TRAIN, EVAL, PREDICT) to separate out different modes of the jobs.\n",
    "Set the mode you are running in your job. Every time the mode changes in your job, please set the current mode. This helps you group steps by mode, for easier analysis. Setting the mode is optional but recommended. If you do not specify this, Tornasole saves all steps under a `GLOBAL` mode. \n",
    "```\n",
    "hook.set_mode(smd.modes.TRAIN)\n",
    "```\n",
    "\n",
    "Refer [DeveloperGuide_MXNet.md](../../DeveloperGuide_MXNet.md) for more details on the APIs Tornasole provides to help you save tensors.\n",
    "\n",
    "### Docker Images with Tornasole\n",
    "\n",
    "We have built SageMaker MXNet containers with smdebug. You can use them from ECR from SageMaker. Here are the links to the images. Please use the image from the appropriate region in which you want your jobs to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker.mxnet import MXNet\n",
    "from smdebug.mxnet import modes\n",
    "\n",
    "# Below changes the region to be one where this notebook is running\n",
    "TAG='latest'\n",
    "REGION = boto3.Session().region_name\n",
    "os.environ['AWS_REGION'] = REGION\n",
    "\n",
    "cpu_docker_image_name= '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-mxnet-1.4.1-cpu:{}'.format(REGION, TAG)\n",
    "#gpu_docker_image_name= '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-mxnet-1.4.1-gpu:{}'.format(REGION, TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the inputs for the training job\n",
    "\n",
    "Now we'll call the Sagemaker MXNet Estimator to kick off a training job along with enabling Tornasole functionality.\n",
    "\n",
    "The *entry_point_script* points to the MXNet training script that has the SessionHook integrated.\n",
    "\n",
    "The *hyperparameters* are the parameters that will be passed to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/mnist_gluon_realtime_visualize_demo.py'\n",
    "hyperparameters = {'batch-size': 256, 'learning_rate': 0.1, 'epochs': 10}\n",
    "base_job_name = 'mxnet-TS-realtime-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                                base_job_name=base_job_name,\n",
    "                                train_instance_count=1,\n",
    "                                train_instance_type='ml.m4.xlarge',\n",
    "                                image_name=cpu_docker_image_name,\n",
    "                                entry_point=entry_point_script,\n",
    "                                hyperparameters=hyperparameters,\n",
    "                                framework_version='1.4.1',\n",
    "                                py_version='py3',\n",
    "                                # following parameter is necesary to instruct SageMaker \n",
    "                                # that debugging data generated by Tornasole needs to be \n",
    "                                # uploaded to S3 bucket in your account. This way we can \n",
    "                                # access it while training job is running.\n",
    "                                debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a fire and forget event. By setting wait=False, we just submit the job to run in the background.\n",
    "# SageMaker will spin off one training job and release control to next cells in the notebook.\n",
    "# Please follow this notebook to see status of the training job.\n",
    "sagemaker_simple_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Result\n",
    "\n",
    "As a result of the above command, SageMaker will spin off 1 training job for you and it will produce the tensors to be analyzed. This job will run in a background without you having to wait for it to complete in order to continue with the rest of the notebook. Because of this async nature of training job we will need to monitor its status so that we don't start to request debugging tensors too early. Tensors are only produced during training phase of SageMaker training job hence let's wait until that begins.\n",
    "\n",
    "### Checking on the training job status\n",
    "\n",
    "We can check the status of the training job by running the following code. It will check on a status of SageMaker training job every five seconds. Once job has started its traning cycle control is released to next cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper method first, to render status status updates\n",
    "import time\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "def print_same_line(s):\n",
    "    sys.stdout.write('\\r{}: {}'.format(strftime('%X', gmtime()), s))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below command will give the status of training job\n",
    "# Note: In the output of below command you will see DebugConfig parameter \n",
    "import time\n",
    "\n",
    "job_name = sagemaker_simple_estimator.latest_training_job.name\n",
    "print('Training job name: ' + job_name)\n",
    "\n",
    "client = sagemaker_simple_estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "\n",
    "if description['TrainingJobStatus'] != 'Completed':\n",
    "    while description['SecondaryStatus'] not in {'Training', 'Completed'}:\n",
    "        description = client.describe_training_job(TrainingJobName=job_name)\n",
    "        primary_status = description['TrainingJobStatus']\n",
    "        secondary_status = description['SecondaryStatus']\n",
    "        print_same_line('Current job status: [PrimaryStatus: {}, SecondaryStatus: {}]'.format(primary_status, secondary_status))\n",
    "        time.sleep(5)\n",
    "\n",
    "# uncomment next line to see full details of training job \n",
    "# client.describe_training_job(TrainingJobName=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving and Analyzing tensors\n",
    "\n",
    "Before getting to analysis, here are some notes on concepts being used in Tornasole that help with analysis.\n",
    "- ***Trial*** - object that is a center piece of Tornasole API when it comes to getting access to tensors. It is a top level abstract that represents a single run of a training job. All tensors emitted by training job are associated with its Trial.\n",
    "- ***Step*** - object that represents next level of abstraction. In Tornasole step is a representation of a single batch of a training job. Each trial has multiple steps. Each tensor is associated with multiple steps - having a particular value at each of the steps.\n",
    "- ***Tensor*** - object that represent actual tensor saved during training job. *Note* - it could be a scalar as well.\n",
    "- ***Mode*** - each DL engine does forward and backward passes during training job. During each of those passes tensors generated by the model are saved. However, in addition to training itself DL engine also uses forward passes for validation phase, and tensors generated during such forward passes are also saved. Tornasole introduces concept of Training Mode in order to allow to differentiate between tensors of each of the phases.\n",
    "\n",
    "For more details on aforementioned concepts as well as on Tornasole API in general (including examples) please refer to [Rules API](../../docs/rules/readme.md)\n",
    "\n",
    "Below, you can find several methods to help with retrieving and plotting tensors. In *get_data* we use concepts described above to retrieve data. We expect to get steps_range that will have 1 or more steps (batches) for which we want to get tensors for. Please note that we are going to retrieve only tensors saved by main training loop and will excluse tensors saved during validation (`mode=modes.TRAIN` will help with that). Two other methods are helpers to plot tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_data(trial, tname, batch_index, steps_range):\n",
    "    tensor = trial.tensor(tname)\n",
    "    vals = []\n",
    "    for s in steps_range:\n",
    "        val = tensor.value(step_num=s, mode=modes.TRAIN)[batch_index][0]\n",
    "        vals.append(val)\n",
    "    return vals\n",
    "\n",
    "def create_plots(steps_range):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(steps_range), constrained_layout=True, figsize=(2*len(steps_range), 2),\n",
    "                            subplot_kw={'xticks': [], 'yticks': []})\n",
    "    return fig, axs\n",
    "\n",
    "def plot_tensors(trial, layer, batch_index, steps_range):\n",
    "    if len(steps_range) > 0:    \n",
    "        fig, axs = create_plots(steps_range)\n",
    "        vals = get_data(trial, layer, batch_index, steps_range)\n",
    "\n",
    "        for ax, image, step in zip(axs.flat if isinstance(axs, np.ndarray) else np.array([axs]), vals, steps_range):\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(str(step))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are prepared with methods to get data and plot it, let's get to it. The goal of the next block is to instantiate a ***Trial***, a central access point for all Tornasole API calls to get tensors. We will do that by inspecting currently running training job and extract necessary params from its debug config to instruct Tornasole where the data we are looking for is located. Couple notes here:\n",
    "- Tensors are being stored in your own S3 bucket to which you can navigate and manually inspect its content if desired.\n",
    "- You might notice a slight delay before trial object is created (last line in the cell). It is normal as Tornasole will monitor corresponding bucket with tensors and wait until tensors appear in it. The delay is introduced by less then instantenous upload of tensors from training container to your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import smdebug.trials\n",
    "from smdebug.trials import S3Trial\n",
    "import logging\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "s3_output_path = description[\"DebugConfig\"][\"DebugHookConfig\"][\"S3OutputPath\"]\n",
    "parse_result = urlparse(s3_output_path)\n",
    "bucket_name = parse_result.netloc\n",
    "prefix_name = parse_result.path.strip('/')\n",
    "\n",
    "logging.getLogger(\"tornasole\").setLevel(logging.INFO)\n",
    "\n",
    "# this is where we create a Trial object that allows access to saved tensors\n",
    "trial = S3Trial(base_job_name, bucket_name, prefix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to inspect all tensors logged by uncommenting below line\n",
    "# trial.tensor_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize tensors of a running training job\n",
    "Now to the final part of our example. Below we will wait until Tornasole has downloaded initial chunk of tensors for us to look at. Once that first chunk is ready - we will keep getting new chunks every 5 seconds and plot their tensors correspondingly one under another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we select the very first tensor from every batch.\n",
    "# Feel free to modify this and select another tensor from the batch.\n",
    "batch_index = 0\n",
    "\n",
    "# This is a name of a tensor to retrieve data of.\n",
    "# Variable is called `layer` as this tensor happens to be output of first convolutional layer.\n",
    "layer = 'conv0_output0'\n",
    "\n",
    "steps = 0\n",
    "while steps == 0:\n",
    "    # trial.steps return all steps that have been downloaded by Tornasole to date.\n",
    "    # It doesn't represent all steps that are to be available once training job is complete -\n",
    "    # it is a snapshot of a current state of the system. If you call it after training job is done\n",
    "    # you will get all tensors available.\n",
    "    steps = trial.steps(mode=modes.TRAIN)\n",
    "    print_same_line('Waiting for tensors to become available...')\n",
    "    time.sleep(3)\n",
    "print('\\nDone')\n",
    "\n",
    "print('Getting tensors and plotting...')\n",
    "rendered_steps = []\n",
    "# trial.training_ended is a way to keep monitoring for a state of a training job as seen by smdebug.\n",
    "# When SageMaker completes training job, trial becomes aware of it.\n",
    "while not trial.training_ended():\n",
    "    steps = trial.steps(mode=modes.TRAIN)\n",
    "    # quick way to get diff between two lists\n",
    "    steps_to_render = list(set(steps).symmetric_difference(set(rendered_steps)))\n",
    "    # plot only tensors from newer chunk\n",
    "    plot_tensors(trial, layer, batch_index, steps_to_render)\n",
    "    rendered_steps.extend(steps_to_render)\n",
    "    time.sleep(5)\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional visualizations\n",
    "\n",
    "Now that we completed plotting of tensors during training job run, let's plot some more tensors. This time we will get all of them at once as training job has finished and Tornasole is aware of all tensors emitted by it. Let's visualize tensors representing weights of first convolutional layer (e.g. its kernels). By inspecting each row of plotted tensors from left to right you can notice progression in how each kernel was \"learning\" its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize weights of the first convolutional layer.\n",
    "layer = 'conv0_weight'\n",
    "\n",
    "for i in range(0, trial.tensor(layer).value(step_num=trial.tensor(layer).steps(mode=modes.TRAIN)[0], mode=modes.TRAIN).shape[0]):\n",
    "    plot_tensors(trial, layer, i, trial.tensor(layer).steps(mode=modes.TRAIN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
